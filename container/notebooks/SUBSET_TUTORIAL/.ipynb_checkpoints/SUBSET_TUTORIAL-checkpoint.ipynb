{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial will walk you through how to download a spatial and variable subset of data.  If you are only interested in a small region of a certain dataset, it is not necessary to downlaod the entire dataset to your local machine. For example, downloading one full orbit of Orbiting Carbon Observatory 2 (OCO-2) Level 1B data from the GES DISC can take several minutes, while downloading a granule of the data takes a matter of seconds. You can learn more about the OCO-2 mission [here](https://oco.jpl.nasa.gov/science/).\n",
    "\n",
    "# Import Dependencies\n",
    "Let's import all the libraries we need. This needs to be done before any of the other cells can be run. These libraries were installed in the docker container you are using, so we will not need to worry about installing anything. Simply running the following cell takes care of all of the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from pydap.cas.urs import setup_session\n",
    "from pydap.client import open_url\n",
    "import numpy as np\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will identify granules in data by looking at the latitude and longitude cooridantes for regions of interest.  In this tutorial, we are interested in extracting a subset of OCO-2 Level 1B radiances within a 5x5 degree box centered at the Mauna Loa volcano in Hawaii."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the appropriate dataset by using DAAC search engines such as OpenSearch or by navigating OPenNDAP directories of datasets. Let's go through these two methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating OPeNDAP Directories\n",
    "Open-source Project for a Network Data Access Protocol, or OPeNDAP, is a protocol for accessing Earth science data.  Let's start by going to an OPeNDAP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Go to the following URL: https://oco2.gesdisc.eosdis.nasa.gov/opendap/hyrax/\n",
    "\n",
    "2. Open the directory: `OCO2_L1B_Science.7r/`\n",
    "\n",
    "3. Open the directory: `2015/`\n",
    "\n",
    "4. Open the directory: `015/`\n",
    "\n",
    "5. Click on the last file: `oco2_L1bScND_02879a_150115_B7000r_150616093751.h5`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are now on an *OpenNDAP Server Dataset Access Form*. From here, you can see the global attriubutes and the variables for this dataset.  Feel free to skim this page to get an idea of what sort of data is contained within OCO-2 Level 1B data. If you wish (not part of this tutorial), you can download the entire data set as a NetCDF-4 File (in the *Action* row)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenSearch to Obtain Subset of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using an OPeNDAP Server Dataset Access Form as shown above, let's use a DAAC search engine to find this same data set. Let's suppose we want granules from 09/01/2014 to 08/31/2015 that have observations near a 5x5 degree of Mauna Loa. A quick search on Google Maps shows that Mauna Loa is located at [-155.590951, 19.472847](https://www.google.com/maps/place/Mauna+Loa/@19.4721389,-155.5943953,17z/data=!3m1!4b1!4m5!3m4!1s0x7953e45a9a2e3483:0x21188532375f4e6b!8m2!3d19.4721389!4d-155.5922066) (longitude, latitude).  We can use OpenSearch to find granules given the spatial or temporal criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Navigate to http://mirador.gsfc.nasa.gov/OpenSearch\n",
    "\n",
    "2. Click on the file: `OCO2_L1B_Science.7r`\n",
    "\n",
    "3. Enter the Start Time: `09/01/2014`\n",
    "\n",
    "4. Enter the End Time: `08/31/2015`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Spatial Box, we are going to input our geophysical region of interest. In our case, we would like a 5x5 degree box.  Therefore the dimensions of our spatial box would be:\n",
    "\n",
    "* -158.09 to -153.09 in Longitude\n",
    "* 16.97 to 22.07 in Latitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&nbsp; &nbsp; 5\\. Enter in the Spatial Box: `-158.09, 16.97, -153.09 ,22.07`\n",
    "<br>\n",
    "<br>\n",
    "These locations (in longitude and latitude) correspond to the west, south, east, and north boundaries, respectively. \n",
    "<br>\n",
    "<br>\n",
    "&nbsp; &nbsp; 6\\. Enter in the Max Results Box: `10000`\n",
    "<br>\n",
    "&nbsp; &nbsp; 7\\. Click submit. \n",
    "<br>\n",
    "<br>\n",
    "The XML file that now appears contains a list of all the URLs that correspond to granules of data from the specified criteria as well as additional information about each granule.\n",
    "<br>\n",
    "<br>\n",
    "Let's store the URLs from this XML document as a text file.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, let's make sure we are in the right directory.  We want to create this text file in the same directory as this Jupyter Notebook. In your terminal, type in the following command:\n",
    "\n",
    "> `cd /home/condauser/tutorials/notebooks/SUBSET_TUTORIAL`\n",
    "<br>\n",
    "\n",
    "Now, let's list the contents of the directory. Run the following command:\n",
    "\n",
    ">`ls`\n",
    "<br>\n",
    "\n",
    "Currently, there should be no existing .txt file.  Now, we will use the `wget`, `grep`, and `egrep` commands to obtain these URLs from the OpenSearch. In your terminal, run the follwoing command:\n",
    "<br>\n",
    "\n",
    ">`wget -q \"http://mirador.gsfc.nasa.gov/cgi-bin/mirador/granlist.pl?searchType=Nominal&format=atom&startTime=2014-09-01T00:00:00Z&endTime=2015-08-31T00:00:00Z&osLocation=-158.09,16.97,-153.09,22.07&maxgranules=10000&dataSet=OCO2_L1B_Science.7r\" -O - | grep 'OPeNDAP HTML' | egrep -o 'href=\\\".*h5.html\\\"' | egrep -o 'http.*html' > URLs.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the URL contains all of the search criteria we entered in OpenSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command also contains GNU three programs that allow us to obtain and parse the correct information.\n",
    "\n",
    "* *wget*: Retrieve a file from the world wide web\n",
    "* *grep*: Pattern matching command, in this case for any line containing 'OPeNDAP HTML'\n",
    "* *egrep*: Extention of grep, in this case pattern matching for any line starting with 'http' and ending with 'html'\n",
    "\n",
    "Notice that the output of *wget* is piped by use of `|` to grep/egrep.  The output of grep/egrep is redirected to URLs.txt by use of `>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a file (URLs.txt) containing all of the URLs that contain the right granules of the data set. You can see this by running the following command in your terminal:\n",
    ">`ls`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Data Format\n",
    "Let's print out all the URLs this command captured. We will leave out the last 5 characters (.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for line in open(\"URLs.txt\", \"r\").readlines():\n",
    "    print(line[:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these URLs is a .h5 file (Hierarchical Data Format 5) that contains the pertinent granules of data for the OCO-2 Level1B dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OPeNDAP URL Suffixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding \".html\" to any of these URLs will take you to the OPeNDAP Data Access Form for that granule. You can download the data from here (not part of this tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding \".ddx\", \".ddx\", \".das\", \".info\", and \".rdf\" returns the metadata for that granule. \".info\" is the most useful in a web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding \".ascii\", \".nc\", \".nc4\", \".dods\" will download the files (to your machine) in various formats such as netCDF-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add \".html\" or \".info\" to get a feel for the suffixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the Geolocation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have URLs that contain the granules of data, let's actually get the subset of data onto our computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following granule from the above list: https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \".html\" to this URL and go to that webpage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the variables\n",
    "\n",
    "1. _SoundingGeometry_sounding_latitude\n",
    "2. _SoundingGeometry_sounding_longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the side of these variable names, you can see the dimensions of both variables: [ = 0..8363][ = 0..7].  This means the latitude and longitude are 2 - dimensional grid that range 0 to 8363 and 0 to 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these dimensions to download specific longitude and latitude data. Since we have already constrained the data to a 5x5 degree window around the volcano, we will just download the entire latitude and longitude data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will first append a \".nc4\" to the .h5 URL.  Then, we will add \"?\" followed by the variable names for latitude and longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5.nc4?_SoundingGeometry_sounding_latitude,_SoundingGeometry_sounding_longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download a netCDF-4 file using this URL.  The following URLs will also return the same netCDF-4 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5.nc4?_SoundingGeometry_sounding_latitude[0:8363][0:7],_SoundingGeometry_sounding_longitude[0:8363][0:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above example, the variables are indexed like any Python list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5.nc4?_SoundingGeometry_sounding_latitude[0:1:8363][0:1:7],_SoundingGeometry_sounding_longitude[0:1:8363][0:1:7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last example: [0:1:8363] means start at index 0, stride by 1, end at index 8362. In other words, [start index, stride integer, stop index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any of the above URLs can be typed into a web browser to obtain a netCDF-4 file containing the pertinent data.  This will download a .nc4 file directly to your machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use the following wget command to download the the file to your local machine (not part of this tutorial).  It will be downloaded as subset_of_oco2_data.nc4.  Replace EarthdataUsername and EarthdataPassword with your Earthdata credentials.  Putting single quotes around your username and password ensure that any special characters are treated as string literals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> wget -O --user='EarthdataUsername' --password='EarthdataPassword' subset_of_oco2_data.nc4 \"https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5.nc4?_SoundingGeometry_sounding_latitude[0:8363][0:7],_SoundingGeometry_sounding_longitude[0:8363][0:7]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Spatial Subsets into Python\n",
    "Now that we've gone through the exercise of locating datasets and creating links that allow you to download subsets of data, let's import data directly from a server into the Jupyter Notebook.  We are giong to make use of the *pydap* package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pydap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can set up a variable to store the original .h5 URL we were working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opendap_url = r'https://oco2.gesdisc.eosdis.nasa.gov/opendap/hyrax/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"r\" in front of the string ensures the URL is read a *raw string literal* so that it ignores special characters (such as \\t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(opendap_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the pydap package to have access to the data set through the URL. Note that we do not need to download the data set in this case. To do this, we are going to need setup a pydap session that will allow us to access the .h5 URL. You're going to need your Earthdata credentials.  Running the next code block will prompt you to enter in your username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "username = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies for the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell. This will set up the a Pydap session where we can access the data from a URL instead of downloading it to your local machine.  It will also remove the *username* and *password* variables that have your Earthdata credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = setup_session(username=username, password=password, check_url=opendap_url)\n",
    "username = ''\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = open_url(opendap_url, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect this data set and see all of the variables and measurments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Data based on a Bounded Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the latitude and longitude data we were working with earlier. We can store the attributes in variables by treating the dataset as a dictionary and inputing the variable names (as seen in the above attributes output) as keys to this dictionary. You will notice that these variable names are consistent with those seen on the OPeNDAP server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sounding_geometry_sounding_latitude = dataset[\"_SoundingGeometry_sounding_latitude\"]\n",
    "sounding_geometry_sounding_longitude = dataset[\"_SoundingGeometry_sounding_longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sounding_geometry_sounding_latitude.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape and size of the data is the same is also consistent with the OPeNDAP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two variables, however, hold the entire longitude and latitude coordinates information.  Remember, we were interested in a 5x5 degree region around Mauna Loa the volcano (-155.59, 19.47). The region was given by the following coordinates:\n",
    "* west: -158.09\n",
    "* south: 16.97\n",
    "* east: -153.09\n",
    "* north: 22.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "west = -158.09\n",
    "south = 16.97\n",
    "east = -153.09\n",
    "north = 22.07\n",
    "region_of_interest = [west, south, east, north]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the *numpy* function, *np.where*, to find the indices of data that match our region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_above_west_south, indices_below_east_north = np.where(  (sounding_geometry_sounding_longitude.data[:] > region_of_interest[0]) \\\n",
    "                                                              & (sounding_geometry_sounding_latitude.data[:] > region_of_interest[1])  \\\n",
    "                                                              & (sounding_geometry_sounding_longitude.data[:] < region_of_interest[2]) \\\n",
    "                                                              & (sounding_geometry_sounding_latitude.data[:] < region_of_interest[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's an example of how np.where works\n",
    "a = np.asarray([1,2,3,4,5])\n",
    "np.where(a > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_above_west_south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_below_east_north"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the indices that correspond to the data for each variable within a 5x5 degree of the volcano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the appropriate indices, let's first get the subset of latitude and longitude coordinates that correspond to this data. We'll create two variables that will be our ranges for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "west_south_slice = slice(indices_above_west_south.min(), indices_above_west_south.max() + 1)\n",
    "east_north_slice = slice(indices_below_east_north.min(), indices_below_east_north.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here's an example of how slices work in Python\n",
    "example_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "example_slice = slice(2,5)\n",
    "print(example_list[example_slice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the subsets of the latitude and longitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitude_subset = dataset[\"_SoundingGeometry_sounding_latitude\"].data[west_south_slice, east_north_slice]\n",
    "longitude_subset = dataset[\"_SoundingGeometry_sounding_longitude\"].data[west_south_slice, east_north_slice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this subset of latitude data to the total latitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Subset Latitude shape:\", latitude_subset.shape)\n",
    "print(\"Total Latitude shape :\", sounding_geometry_sounding_latitude.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that we have greatly reduced the amount of data we will need by focusing on the data in a 5x5 degree box around the volcano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the subsets of the actual measurements we want. In this case, O2 Radiance, Strong CO2 Radiance, and Weak CO2 Radiance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "radiance_O2_subset = dataset[\"_SoundingMeasurements_radiance_o2\"].data[west_south_slice, east_north_slice]\n",
    "radiance_strong_CO2_subset = dataset[\"_SoundingMeasurements_radiance_strong_co2\"].data[west_south_slice, east_north_slice]\n",
    "radiance_weak_CO2_subset = dataset[\"_SoundingMeasurements_radiance_weak_co2\"].data[west_south_slice, east_north_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "radiance_O2_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now succesfully obtained a subset of data from a server without having to download a large file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use Basemap to plot some of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_min = np.min(latitude_subset)\n",
    "lat_max = np.max(latitude_subset)\n",
    "lon_min = np.min(longitude_subset)\n",
    "lon_max = np.max(longitude_subset)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line in the above box ensures that any plot will appear within the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_min, lon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_max, lon_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = Basemap(llcrnrlon=lon_max, llcrnrlat=lat_min, urcrnrlon=lon_min, urcrnrlat=lat_max, resolution='l', projection='aeqd', lon_0=0, lat_0=0)\n",
    "\n",
    "\n",
    "m.bluemarble()\n",
    "pc = m.pcolor(longitude_subset, latitude_subset, radiance_weak_CO2_subset[:,:,0], latlon=True)\n",
    "cbar = m.colorbar(pc, location=\"bottom\", pad=\"5%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the data for the Weak CO2 Radiance move across the diagonal of the map projection.  Only one of the several .h5 URLs was used to create this image (hence the single streak of data across the map)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a URL for a Spatial Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of reading in the spatial subset as shown above (Reading Spatial Subsets into Python), we can construct a URL based on the indices that match data in a 5x5 degree region around Mauna Loa. Then, you can use this URL to download the granule directly to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_above_west_south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_below_east_north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.min(indices_above_west_south), np.max(indices_above_west_south))\n",
    "print(np.min(indices_below_east_north), np.max(indices_below_east_north))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will start with our original .h5 URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will append \".nc4?\" and the subset of variables and indices we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \".nc4?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can add the variable name and the indeces that corresponds to the data above the volcano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"__SoundingGeometry_sounding_latitude[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"__SoundingGeometry_sounding_longitude[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"__SoundingGeometry_sounding_time_tai93[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"__SoundingMeasurements_radiance_o2[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"__SoundingMeasurements_radiance_strong_co2[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"__SoundingMeasurements_radiance_weak_co2[5992:6246][0:7]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you click on the above URL, a .nc4 file will download directly to your machine.  Alternatively, you can use *wget* to obtain the data from the above URL as shown above (Obtaining the Geolocation Data)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
