{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This tutorial will walk you through how to download a spatial and variable subset of data.  If you are only interested in a small region of a certain dataset, it is not necessary to downlaod the entire dataset to your local machine. For example, downloading one full orbit of Orbiting Carbon Observatory 2 (OCO-2) Level 1B data from the GES DISC can take several minutes, while downloading a granule of the data takes a matter of seconds. You can learn more about the OCO-2 mission [here](https://oco.jpl.nasa.gov/science/).\n",
    "\n",
    "# Import Dependencies\n",
    "Let's import all the libraries we need. This needs to be done before any of the other cells can be run. These libraries were installed in the docker container you are using, so we will not need to worry about installing anything. Simply running the following cell takes care of all of the dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "from pydap.cas.urs import setup_session\n",
    "from pydap.client import open_url\n",
    "import numpy as np\n",
    "import netCDF4\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procedure\n",
    "\n",
    "We will identify granules in data by looking at the latitude and longitude cooridantes for regions of interest.  In this tutorial, we are interested in extracting a subset of OCO-2 Level 1B radiances within a 5x5 degree box centered at the Mauna Loa volcano in Hawaii.\n",
    "\n",
    "## Finding the Data Set\n",
    "\n",
    "We can find the appropriate dataset by using DAAC search engines such as OpenSearch or by navigating OPenNDAP directories of datasets. Let's go through these two methods.\n",
    "\n",
    "### Navigating OPeNDAP Directories\n",
    "Open-source Project for a Network Data Access Protocol, or OPeNDAP, is a protocol for accessing Earth science data.  Let's start by going to an OPeNDAP server.\n",
    "\n",
    "1. Go to the following URL: https://oco2.gesdisc.eosdis.nasa.gov/opendap/hyrax/\n",
    "\n",
    "2. Open the directory: `OCO2_L1B_Science.7r/`\n",
    "\n",
    "3. Open the directory: `2015/`\n",
    "\n",
    "4. Open the directory: `015/`\n",
    "\n",
    "5. Click on the last file: `oco2_L1bScND_02879a_150115_B7000r_150616093751.h5`\n",
    "\n",
    "You are now on an *OpenNDAP Server Dataset Access Form*. From here, you can see the global attriubutes and the variables for this dataset.  Feel free to skim this page to get an idea of what sort of data is contained within OCO-2 Level 1B data. If you wish (*not part of this tutorial*), you can download the entire data set as a NetCDF-4 File (in the *Action* row)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OpenSearch to Obtain Subset of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using an OPeNDAP Server Dataset Access Form as shown above, let's use a DAAC search engine to find this same data set. Let's suppose we want granules from 09/01/2014 to 08/31/2015 that have observations near a 5x5 degree of Mauna Loa. A quick search on Google Maps shows that Mauna Loa is located at [-155.590951, 19.472847](https://www.google.com/maps/place/Mauna+Loa/@19.4721389,-155.5943953,17z/data=!3m1!4b1!4m5!3m4!1s0x7953e45a9a2e3483:0x21188532375f4e6b!8m2!3d19.4721389!4d-155.5922066) (longitude, latitude).  We can use OpenSearch to find granules given the spatial and temporal criteria.  We will use the *wget* command to download a list of URLs which we can access data granules from."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "First, let's make sure we are in the right directory.  We want to create this text file in the same directory as this Jupyter Notebook. In your terminal, type in the following command:\n",
    "\n",
    "> `cd /home/condauser/tutorials/notebooks/SUBSET_TUTORIAL`\n",
    "<br>\n",
    "\n",
    "Now, let's list the contents of the directory. Run the following command:\n",
    "\n",
    ">`ls`\n",
    "<br>\n",
    "\n",
    "Currently, there should be no existing .txt file.  Now, we will use the `wget`, `grep`, and `egrep` commands to obtain these URLs from the OpenSearch. In your terminal, run the follwoing command:\n",
    "<br>\n",
    "\n",
    ">`wget -q \"http://mirador.gsfc.nasa.gov/cgi-bin/mirador/granlist.pl?searchType=Nominal&format=atom&startTime=2014-09-01T00:00:00Z&endTime=2015-08-31T00:00:00Z&osLocation=-158.09,16.97,-153.09,22.07&maxgranules=10000&dataSet=OCO2_L1B_Science.7r\" -O - | grep 'OPeNDAP HTML' | egrep -o 'href=\\\".*h5.html\\\"' | egrep -o 'http.*html' > URLs.txt`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the *wget* URL contains all of the search criteria we desired:\n",
    "\n",
    "* startTime=2014-09-01\n",
    "* endTime=2015-08-31\n",
    "* Location=-158.09,16.97,-153.09,22.07\n",
    "* dataSet=OCO2_L1B_Science.7r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The command also contains GNU three programs that allow us to obtain and parse the correct information.\n",
    "\n",
    "* *wget*: Retrieve a file from the world wide web\n",
    "* *grep*: Pattern matching command, in this case for any line containing 'OPeNDAP HTML'\n",
    "* *egrep*: Extention of grep, in this case pattern matching for any line starting with 'http' and ending with 'html'\n",
    "\n",
    "Notice that the output of *wget* is piped by use of `|` to grep/egrep.  The output of grep/egrep is redirected to URLs.txt by use of `>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a file (URLs.txt) containing all of the URLs that contain the right granules of the data set. You can see this by running the following command in your terminal:\n",
    ">`ls`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Data Format\n",
    "Let's print out all the URLs this command captured. We will leave out the last 5 characters (.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open(\"URLs.txt\", \"r\").readlines():\n",
    "    print(line[:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these URLs is a .h5 file (Hierarchical Data Format 5) that contains the pertinent granules of data for the OCO-2 Level1B dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using OPeNDAP URL Suffixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding \".html\" to any of these URLs will take you to the OPeNDAP Data Access Form for that granule. You can download the data from here (not part of this tutorial)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding \".ddx\", \".ddx\", \".das\", \".info\", and \".rdf\" returns the metadata for that granule. \".info\" is the most useful in a web browser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding \".ascii\", \".nc\", \".nc4\", \".dods\" will download the files (to your machine) in various formats such as netCDF-4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to add \".html\" or \".info\" to get a feel for the suffixes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Spatial Subsets into Python\n",
    "Now that we've gone through the exercise of locating datasets, let's import data directly from a server into the Jupyter Notebook.  We are giong to make use of the *pydap* package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pydap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the following URL. It is one of the URLs from `URLs.txt`.\n",
    "\n",
    "https://oco2.gesdisc.eosdis.nasa.gov/opendap/hyrax/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add \".html\" to the end of the URL and navigate to that website. You will notice the following variables:\n",
    "\n",
    "1. _SoundingGeometry_sounding_latitude\n",
    "2. _SoundingGeometry_sounding_longitude\n",
    "3. _SoundingMeasurements_radiance_weak_co2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opendap_url = r'https://oco2.gesdisc.eosdis.nasa.gov/opendap/hyrax/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"r\" in front of the string ensures the URL is read a *raw string literal* so that it ignores special characters (such as \\t)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opendap_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the pydap package to have access to the data set through the URL. Note that we do not need to download the data set in this case. To do this, we are going to need setup a pydap session that will allow us to access the .h5 URL. You're going to need your Earthdata credentials.  Running the next code block will prompt you to enter in your username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "username = input(\"input your username: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same applies for the next code block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell. This will set up the a Pydap session where we can access the data from a URL instead of downloading it to your local machine.  It will also remove the *username* and *password* variables that have your Earthdata credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = setup_session(username=username, password=password, check_url=opendap_url)\n",
    "username = ''\n",
    "password = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = open_url(opendap_url, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect this data set and see all of the variables and measurments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Data based on a Bounded Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's grab the latitude and longitude data we were working with earlier. We can store the attributes in variables by treating the dataset as a dictionary and inputing the variable names (as seen in the above attributes output) as keys to this dictionary. You will notice that these variable names are consistent with those seen on the OPeNDAP server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sounding_geometry_sounding_latitude = dataset[\"_SoundingGeometry_sounding_latitude\"]\n",
    "sounding_geometry_sounding_longitude = dataset[\"_SoundingGeometry_sounding_longitude\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sounding_geometry_sounding_latitude.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape and size of the data is the same is also consistent with the OPeNDAP server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two variables, however, hold the entire longitude and latitude coordinates information.  Remember, we were interested in a 5x5 degree region around Mauna Loa the volcano (-155.59, 19.47). The region was given by the following coordinates:\n",
    "* west: -158.09\n",
    "* south: 16.97\n",
    "* east: -153.09\n",
    "* north: 22.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "west = -158.09\n",
    "south = 16.97\n",
    "east = -153.09\n",
    "north = 22.07\n",
    "region_of_interest = [west, south, east, north]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the *numpy* function, *np.where*, to find the indices of data that match our region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_above_west_south, indices_below_east_north = np.where(  (sounding_geometry_sounding_longitude.data[:] > region_of_interest[0]) \\\n",
    "                                                              & (sounding_geometry_sounding_latitude.data[:] > region_of_interest[1])  \\\n",
    "                                                              & (sounding_geometry_sounding_longitude.data[:] < region_of_interest[2]) \\\n",
    "                                                              & (sounding_geometry_sounding_latitude.data[:] < region_of_interest[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example of how np.where works\n",
    "a = np.asarray([1,2,3,4,5])\n",
    "np.where(a > 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_above_west_south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_below_east_north"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have the indices that correspond to the data for each variable within a 5x5 degree of the volcano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the appropriate indices, let's first get the subset of latitude and longitude coordinates that correspond to this data. We'll create two variables that will be our ranges for indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "west_south_slice = slice(indices_above_west_south.min(), indices_above_west_south.max() + 1)\n",
    "east_north_slice = slice(indices_below_east_north.min(), indices_below_east_north.max() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example of how slices work in Python\n",
    "example_list = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h']\n",
    "example_slice = slice(2,5)\n",
    "print(example_list[example_slice])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the subsets of the latitude and longitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latitude_subset = dataset[\"_SoundingGeometry_sounding_latitude\"].data[west_south_slice, east_north_slice]\n",
    "longitude_subset = dataset[\"_SoundingGeometry_sounding_longitude\"].data[west_south_slice, east_north_slice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this subset of latitude data to the total latitude data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Subset Latitude shape:\", latitude_subset.shape)\n",
    "print(\"Total Latitude shape :\", sounding_geometry_sounding_latitude.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clear that we have greatly reduced the amount of data we will need by focusing on the data in a 5x5 degree box around the volcano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get the subsets of the actual measurements we want. In this case, O2 Radiance, Strong CO2 Radiance, and Weak CO2 Radiance.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_O2_subset = dataset[\"_SoundingMeasurements_radiance_o2\"].data[west_south_slice, east_north_slice]\n",
    "radiance_strong_CO2_subset = dataset[\"_SoundingMeasurements_radiance_strong_co2\"].data[west_south_slice, east_north_slice]\n",
    "radiance_weak_CO2_subset = dataset[\"_SoundingMeasurements_radiance_weak_co2\"].data[west_south_slice, east_north_slice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_O2_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now succesfully obtained a subset of data from a server without having to download a large file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_O2_subset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use Basemap to plot some of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_min = np.min(latitude_subset)\n",
    "lat_max = np.max(latitude_subset)\n",
    "lon_min = np.min(longitude_subset)\n",
    "lon_max = np.max(longitude_subset)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last line in the above box ensures that any plot will appear within the Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min, lon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_max, lon_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap(llcrnrlon=lon_min, llcrnrlat=lat_min, urcrnrlon=lon_max, urcrnrlat=lat_max, resolution='l', projection='aeqd', lon_0=0, lat_0=0)\n",
    "\n",
    "\n",
    "m.bluemarble()\n",
    "pc = m.pcolor(longitude_subset, latitude_subset, radiance_weak_CO2_subset[:,:,0], latlon=True)\n",
    "cbar = m.colorbar(pc, location=\"bottom\", pad=\"5%\")\n",
    "cbar.set_label(\"photons/m^2/sr/um\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the data for the Weak CO2 Radiance band move across the diagonal of the map projection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a URL for a Spatial Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of reading in the spatial subset as shown above (Reading Spatial Subsets into Python) using the *pydap* package, we can construct a URL based on the indices that match data in a 5x5 degree region around Mauna Loa. Then, you can use this URL to download the granule directly to your local machine. From here, we can use the *netCDF4* package to plot the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already found the indices that match to the data over a 5x5 degree region around the volcano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_above_west_south"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_below_east_north"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(np.min(indices_above_west_south), np.max(indices_above_west_south))\n",
    "print(np.min(indices_below_east_north), np.max(indices_below_east_north))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will start with our original .h5 URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will append \".nc4?\" and the subset of variables and indices we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \".nc4?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can add the variable name and the indeces that corresponds to the data above the volcano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"_SoundingGeometry_sounding_latitude[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"_SoundingGeometry_sounding_longitude[5992:6246][0:7],\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = url + \"_SoundingMeasurements_radiance_weak_co2[5992:6246][0:7][0:1015]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the radiance measurment has a third dimension: `[0:1015]`. You can see this by examining the shape of the radiance variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radiance_weak_CO2_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you click on the above URL (*not part of this tutorial*), a .nc4 file will download directly to your machine.  Alternatively, we can use *wget* to obtain the data from the above URL.  You will need your Earthdata login info.\n",
    "<br><br>\n",
    "We need to input your username and password for earthdata login. Run the following command and enter your username and password when prompted:\n",
    "\n",
    "> `read -p \"enter your username: \" username; read -s -p \"enter your password: \" password; echo \"\"`\n",
    "\n",
    "Now, we will use the *wget* commnad to obtain a subset of data using the URL we just built.\n",
    "\n",
    "> `cd /home/condauser/tutorials/notebooks/SUBSET_TUTORIAL`\n",
    "\n",
    "> `wget --user=\"$username\" --password=\"$password\" -O subset.nc4  \"https://oco2.gesdisc.eosdis.nasa.gov/opendap/OCO2_L1B_Science.7r/2015/015/oco2_L1bScND_02879a_150115_B7000r_150616093751.h5.nc4?_SoundingGeometry_sounding_latitude[5992:6246][0:7],_SoundingGeometry_sounding_longitude[5992:6246][0:7],_SoundingMeasurements_radiance_weak_co2[5992:6246][0:7][0:1015]\"; username=\"\"; password=\"\"`\n",
    "\n",
    "If you run the following command, you will see `subset.nc4` in your directory.\n",
    "\n",
    "> `ls`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use *netCDF4* to examine this downloaded subset. To learn more about using *netCDF4*, check out the `ACOS_DATA_HANDLING` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = netCDF4.Dataset(\"subset.nc4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in data.variables:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_nc4 = data[\"_SoundingGeometry_sounding_latitude\"][:]\n",
    "lon_nc4 = data[\"_SoundingGeometry_sounding_longitude\"][:]\n",
    "rad_nc4 = data[\"_SoundingMeasurements_radiance_weak_co2\"][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_nc4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_nc4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the shape of the data from the downloaded `.nc4` file is the same as the shape of the data from the *pydap* server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rad_nc4.shape == radiance_weak_CO2_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lats_min = lat_nc4.min()\n",
    "lats_max = lat_nc4.max()\n",
    "lons_min = lon_nc4.min()\n",
    "lons_max = lon_nc4.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Basemap(llcrnrlon=lons_min, llcrnrlat=lats_min, urcrnrlon=lons_max, urcrnrlat=lats_max, resolution='l', projection='aeqd', lon_0=0, lat_0=0)\n",
    "\n",
    "\n",
    "m.bluemarble()\n",
    "pc = m.pcolor(lon_nc4, lat_nc4, rad_nc4[:,:,0], latlon=True)\n",
    "cbar = m.colorbar(pc, location=\"bottom\", pad=\"5%\")\n",
    "cbar.set_label(\"photons/m^2/sr/um\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can see that the downloaded `.nc4` map agrees with the map produced by the data from the *pydap* server."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
